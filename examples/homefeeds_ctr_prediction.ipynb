{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib as imp\n",
    "import sys\n",
    "import numpy as np\n",
    "sys.path = list(set(sys.path + ['../../']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"5\"\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "NUM_TOTAL_ITEMS = 69669"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Metric\n",
    "import recsys.metrics.auc as auc\n",
    "auc = imp.reload(auc)\n",
    "auc_evaluator = auc.AUC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "data_all = np.loadtxt('../data/train_data.dat', delimiter='\\t',\n",
    "                dtype={'names': ('user_id', 'item_id', 'label'), 'formats': ('<i8', '<i8', '<i8')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7875325 2625109\n"
     ]
    }
   ],
   "source": [
    "# Split Train/Test\n",
    "from sklearn.model_selection import train_test_split\n",
    "data_train, data_test = train_test_split(data_all)\n",
    "print(len(data_train), len(data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset\n",
    "import recsys.dataset as dataset\n",
    "dataset = imp.reload(dataset)\n",
    "train_dataset = dataset.Dataset(data_train, total_users=None, total_items=NUM_TOTAL_ITEMS,\n",
    "                                implicit_negative=False, name='Train')\n",
    "test_dataset = dataset.Dataset(data_test, total_users=None, total_items=NUM_TOTAL_ITEMS,\n",
    "                               implicit_negative=False, name='Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init all feature dict begin:\n",
      "loading: ../data/data_formal/user_info/user_profile_new.res\n",
      "loading: ../data/data_formal/user_info/user_satisfied_his_json.txt\n",
      "loading: ../data/data_formal/item_info/item_id_meta_info.txt\n",
      "loading: ../data/data_formal/item_info/home_feed_reaction_stat.txt\n",
      "loading: ../data/data_formal/item_info/item_play_info.txt\n",
      "loading: ../data/data_formal/user_info/user_profile_new.res ../data/data_formal/user_info/user_short_video_info.txt\n",
      "init all feature dict done.\n",
      "init all index map begin:\n",
      "init all index map done.\n"
     ]
    }
   ],
   "source": [
    "# Create Featurizer\n",
    "import homefeeds_featurizer\n",
    "homefeeds_featurizer = imp.reload(homefeeds_featurizer)\n",
    "featurizer = homefeeds_featurizer.HomeFeedDataSet(\"../data/data_formal/\", default_item_len=20,\n",
    "                             user_info_sub_dir =\"user_info/\", item_info_sub_dir = \"item_info/\")\n",
    "#featurizer = homefeeds_featurizer.HomeFeedDataSet(\"../data/data_formal/\", default_item_len=20,\n",
    "#                             user_info_sub_dir =\"user_info_test/\", item_info_sub_dir = \"item_info/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test users: 280\n"
     ]
    }
   ],
   "source": [
    "# Create Sampler\n",
    "# create data sampler for training and testing\n",
    "import recsys.samplers.feeds_sampler as feeds_sampler\n",
    "feeds_sampler = imp.reload(feeds_sampler)\n",
    "train_sampler = feeds_sampler.create_training_sampler(\n",
    "    dataset=train_dataset, featurizer=featurizer, max_pos_neg_per_user=5, batch_size=10, num_process=1, seed=100)\n",
    "test_sampler = feeds_sampler.create_evaluation_sampler(\n",
    "    dataset=test_dataset, featurizer=featurizer, max_pos_neg_per_user=30, seed=10)\n",
    "print(\"test users: {}\".format(len(test_dataset.warm_users(30))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fea_user_demography_dim: 123\n",
      "fea_user_stat_dim: 1944\n",
      "fea_user_history_dim: 20\n",
      "fea_item_meta_dim: 59226\n",
      "fea_item_stat_dim: 5\n",
      "fea_context_hour_dim: 1\n"
     ]
    }
   ],
   "source": [
    "fea_user_demography_dim = featurizer.fea_user_demography_dim()\n",
    "fea_user_stat_dim = featurizer.fea_user_stat_dim()\n",
    "fea_user_history_dim = featurizer.fea_user_history_dim()\n",
    "fea_item_meta_dim = featurizer.fea_item_meta_dim()\n",
    "fea_item_stat_dim = featurizer.fea_item_stat_dim()\n",
    "fea_context_hour_dim = featurizer.fea_context_hour_dim()\n",
    "print(\"fea_user_demography_dim: {}\".format(fea_user_demography_dim))\n",
    "print(\"fea_user_stat_dim: {}\".format(fea_user_stat_dim))\n",
    "print(\"fea_user_history_dim: {}\".format(fea_user_history_dim))\n",
    "print(\"fea_item_meta_dim: {}\".format(fea_item_meta_dim))\n",
    "print(\"fea_item_stat_dim: {}\".format(fea_item_stat_dim))\n",
    "print(\"fea_context_hour_dim: {}\".format(fea_context_hour_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Model\n",
    "import recsys.recommenders.feeds_fm_recommender as feeds_fm_recommender\n",
    "feeds_fm_recommender = imp.reload(feeds_fm_recommender)\n",
    "model = feeds_fm_recommender.FeedsFMRecommender(\n",
    "    fea_user_demography_dim=fea_user_demography_dim, fea_user_stat_dim=fea_user_stat_dim, fea_user_history_dim=fea_user_history_dim,\n",
    "    fea_item_meta_dim=fea_item_meta_dim, fea_item_stat_dim=fea_item_stat_dim, fea_context_hour_dim=fea_context_hour_dim,\n",
    "    total_item_num=NUM_TOTAL_ITEMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/work/anaconda3/envs/tf13/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/work/anaconda3/envs/tf13/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "# Create Trainer\n",
    "import recsys.model_trainer as model_trainer\n",
    "model_trainer = imp.reload(model_trainer)\n",
    "trainer = model_trainer.ModelTrainer(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-08 18:01:17.731263\n"
     ]
    }
   ],
   "source": [
    "# Start Training\n",
    "import datetime\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[Training starts, total_iter: 100, eval_iter: 5, save_iter: 5]\u001b[0m\n",
      "\u001b[31m[iter 5]\u001b[0m Model saved.\n",
      "\u001b[31m[iter 5]\u001b[0m loss: nan\n",
      "\u001b[32m..(dataset: Test) evaluation\u001b[0m\n",
      "WARNING:tensorflow:From /home/work/anaconda3/envs/tf13/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from FeedsFMRec/model.ckpt\n",
      "...Evaluated 1 users\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work/anaconda3/envs/tf13/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/work/anaconda3/envs/tf13/lib/python3.7/site-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m..(dataset: Test)\u001b[0m AUC nan\n",
      "\u001b[31m[iter 10]\u001b[0m Model saved.\n",
      "\u001b[31m[iter 10]\u001b[0m loss: nan\n",
      "\u001b[32m..(dataset: Test) evaluation\u001b[0m\n",
      "INFO:tensorflow:Restoring parameters from FeedsFMRec/model.ckpt\n",
      "\u001b[32m..(dataset: Test)\u001b[0m AUC nan\n",
      "\u001b[31m[iter 15]\u001b[0m Model saved.\n",
      "\u001b[31m[iter 15]\u001b[0m loss: nan\n",
      "\u001b[32m..(dataset: Test) evaluation\u001b[0m\n",
      "INFO:tensorflow:Restoring parameters from FeedsFMRec/model.ckpt\n",
      "\u001b[32m..(dataset: Test)\u001b[0m AUC nan\n",
      "\u001b[31m[iter 20]\u001b[0m Model saved.\n",
      "\u001b[31m[iter 20]\u001b[0m loss: nan\n",
      "\u001b[32m..(dataset: Test) evaluation\u001b[0m\n",
      "INFO:tensorflow:Restoring parameters from FeedsFMRec/model.ckpt\n",
      "\u001b[32m..(dataset: Test)\u001b[0m AUC nan\n",
      "\u001b[31m[iter 25]\u001b[0m Model saved.\n",
      "\u001b[31m[iter 25]\u001b[0m loss: nan\n",
      "\u001b[32m..(dataset: Test) evaluation\u001b[0m\n",
      "INFO:tensorflow:Restoring parameters from FeedsFMRec/model.ckpt\n",
      "\u001b[32m..(dataset: Test)\u001b[0m AUC nan\n",
      "\u001b[31m[iter 30]\u001b[0m Model saved.\n",
      "\u001b[31m[iter 30]\u001b[0m loss: nan\n",
      "\u001b[32m..(dataset: Test) evaluation\u001b[0m\n",
      "INFO:tensorflow:Restoring parameters from FeedsFMRec/model.ckpt\n",
      "\u001b[32m..(dataset: Test)\u001b[0m AUC nan\n",
      "\u001b[31m[iter 35]\u001b[0m Model saved.\n",
      "\u001b[31m[iter 35]\u001b[0m loss: nan\n",
      "\u001b[32m..(dataset: Test) evaluation\u001b[0m\n",
      "INFO:tensorflow:Restoring parameters from FeedsFMRec/model.ckpt\n",
      "\u001b[32m..(dataset: Test)\u001b[0m AUC nan\n",
      "\u001b[31m[iter 40]\u001b[0m Model saved.\n",
      "\u001b[31m[iter 40]\u001b[0m loss: nan\n",
      "\u001b[32m..(dataset: Test) evaluation\u001b[0m\n",
      "INFO:tensorflow:Restoring parameters from FeedsFMRec/model.ckpt\n",
      "\u001b[32m..(dataset: Test)\u001b[0m AUC nan\n",
      "\u001b[31m[iter 45]\u001b[0m Model saved.\n",
      "\u001b[31m[iter 45]\u001b[0m loss: nan\n",
      "\u001b[32m..(dataset: Test) evaluation\u001b[0m\n",
      "INFO:tensorflow:Restoring parameters from FeedsFMRec/model.ckpt\n",
      "...Evaluated 140 users\r"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "trainer.train(total_iter=100, \n",
    "                    eval_iter=5,\n",
    "                    save_iter=5,\n",
    "                    train_sampler=train_sampler,\n",
    "                    eval_samplers=[test_sampler], \n",
    "                    evaluators=[auc_evaluator])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finish Training\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export Protobuf model for online serving\n",
    "!rm -rf ./pbModel\n",
    "model.export(export_model_dir=\"pbModel\", as_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect internal graph weights\n",
    "def inspect_weights(checkpoint_model_dir):\n",
    "    reader = tf.train.NewCheckpointReader(checkpoint_model_dir)\n",
    "    variables = reader.get_variable_to_shape_map()\n",
    "    for var, shape in variables.items():\n",
    "        trained_weight = reader.get_tensor(var)\n",
    "        print(\"VarName: {}\".format(var))\n",
    "        print(\"VarShape: {}\".format(shape))\n",
    "        print(\"VarValue: {}\".format(trained_weight))\n",
    "inspect_weights(\"./FeedsFMRec/model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect internal op tensor value of testing\n",
    "b = test_sampler.next_batch()\n",
    "print(\"data:\", b)\n",
    "print(\"score:\", model.serve_inspect_ports(batch_data=b[1], ports=model.servegraph.get_outputs()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
