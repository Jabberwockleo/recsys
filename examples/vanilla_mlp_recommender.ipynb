{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '/anaconda3/lib/python3.6', '/anaconda3/lib/python36.zip', '/anaconda3/lib/python3.6/site-packages', '/anaconda3/lib/python3.6/site-packages/IPython/extensions', '/Users/leowan/Desktop/git/', '/anaconda3/lib/python3.6/lib-dynload', '/anaconda3/lib/python3.6/site-packages/aeosa', '/Users/leowan/.ipython']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "tmp = set(sys.path)\n",
    "tmp.add(\"/Users/leowan/Desktop/git/\")\n",
    "sys.path = list(tmp)\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download dataset\n",
    "# download datasets\n",
    "import urllib.request\n",
    "dataset_prefix = 'http://s3.amazonaws.com/cornell-tech-sdl-openrec'\n",
    "urllib.request.urlretrieve('%s/lastfm/lastfm_test.npy' % dataset_prefix, \n",
    "                   'lastfm_test.npy')\n",
    "urllib.request.urlretrieve('%s/lastfm/lastfm_train.npy' % dataset_prefix, \n",
    "                   'lastfm_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import recsys.recommenders.recommender_base as recommender_base\n",
    "import recsys.modules.extractions.embedding_layer as embedding_layer\n",
    "import recsys.modules.interactions.mlp_softmax as mlp_softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import imp\n",
    "recommender_base = imp.reload(recommender_base)\n",
    "embedding_layer = imp.reload(embedding_layer)\n",
    "mlp_softmax = imp.reload(mlp_softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def VanlillaMlpRec(batch_size, dim_item_embed, max_seq_len, total_items,\n",
    "        l2_reg_embed=None, l2_reg_mlp=None, dropout=None, init_model_dir=None,\n",
    "        save_model_dir='VanlillaMlpRec/', train=True, serve=False):\n",
    "    \n",
    "    rec = recommender_base.Recommender(init_model_dir=init_model_dir,\n",
    "                      save_model_dir=save_model_dir, train=train, serve=serve)\n",
    "\n",
    "    \n",
    "    @rec.traingraph.inputgraph(outs=['seq_item_id', 'seq_len', 'label'])\n",
    "    def train_input_graph(subgraph):\n",
    "      \n",
    "        subgraph['seq_item_id'] = tf.placeholder(tf.int32, \n",
    "                                      shape=[batch_size, max_seq_len],\n",
    "                                      name='seq_item_id')\n",
    "        subgraph['seq_len'] = tf.placeholder(tf.int32, \n",
    "                                      shape=[batch_size], \n",
    "                                      name='seq_len')\n",
    "        subgraph['label'] = tf.placeholder(tf.int32, \n",
    "                                      shape=[batch_size], \n",
    "                                      name='label')\n",
    "        \n",
    "        subgraph.register_global_input_mapping({'seq_item_id': subgraph['seq_item_id'],\n",
    "                                                'seq_len': subgraph['seq_len'],\n",
    "                                                'label': subgraph['label']})\n",
    "        \n",
    "        \n",
    "    @rec.servegraph.inputgraph(outs=['seq_item_id', 'seq_len'])\n",
    "    def serve_input_graph(subgraph):\n",
    "        subgraph['seq_item_id'] = tf.placeholder(tf.int32, \n",
    "                                      shape=[None, max_seq_len],\n",
    "                                      name='seq_item_id')\n",
    "        subgraph['seq_len'] = tf.placeholder(tf.int32, \n",
    "                                      shape=[None],\n",
    "                                      name='seq_len')\n",
    "        subgraph.register_global_input_mapping({'seq_item_id': subgraph['seq_item_id'],\n",
    "                                                'seq_len': subgraph['seq_len']})\n",
    "\n",
    "    \n",
    "    @rec.traingraph.itemgraph(ins=['seq_item_id'], outs=['seq_vec'])\n",
    "    @rec.servegraph.itemgraph(ins=['seq_item_id'], outs=['seq_vec'])\n",
    "    def item_graph(subgraph):\n",
    "        _, subgraph['seq_vec']= embedding_layer.apply(l2_reg=l2_reg_embed,\n",
    "                                      init='normal',\n",
    "                                      id_=subgraph['seq_item_id'],\n",
    "                                      shape=[total_items,dim_item_embed],\n",
    "                                      subgraph=subgraph,\n",
    "                                      scope='item')\n",
    "        \n",
    "    \n",
    "    @rec.traingraph.interactiongraph(ins=['seq_vec', 'seq_len', 'label'])\n",
    "    def train_interaction_graph(subgraph):\n",
    "        mlp_softmax.apply(user=None,\n",
    "                   item=subgraph['seq_vec'],\n",
    "                   seq_len=subgraph['seq_len'],\n",
    "                   max_seq_len=max_seq_len,\n",
    "                   dims=[dim_item_embed, total_items],\n",
    "                   l2_reg=l2_reg_mlp,\n",
    "                   labels=subgraph['label'],\n",
    "                   dropout=dropout,\n",
    "                   train=True,\n",
    "                   subgraph=subgraph,\n",
    "                   scope='MLPSoftmax'\n",
    "                  )\n",
    "\n",
    "        \n",
    "    @rec.servegraph.interactiongraph(ins=['seq_vec', 'seq_len'])\n",
    "    def serve_interaction_graph(subgraph):\n",
    "        mlp_softmax.apply(user=None,\n",
    "                   item=subgraph['seq_vec'],\n",
    "                   seq_len=subgraph['seq_len'],\n",
    "                   max_seq_len=max_seq_len,\n",
    "                   dims=[dim_item_embed, total_items],\n",
    "                   l2_reg=l2_reg_mlp,\n",
    "                   train=False,\n",
    "                   subgraph=subgraph,\n",
    "                   scope='MLPSoftmax'\n",
    "                   )\n",
    "\n",
    "        \n",
    "    @rec.traingraph.optimizergraph\n",
    "    def optimizer_graph(subgraph):\n",
    "        losses = tf.add_n(subgraph.get_global_losses())\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "        subgraph.register_global_operation(optimizer.minimize(losses))\n",
    "    \n",
    "    \n",
    "    @rec.traingraph.connector\n",
    "    @rec.servegraph.connector\n",
    "    def connect(graph):\n",
    "        graph.itemgraph['seq_item_id'] = graph.inputgraph['seq_item_id']\n",
    "        graph.interactiongraph['seq_len'] = graph.inputgraph['seq_len']\n",
    "        graph.interactiongraph['seq_vec'] = graph.itemgraph['seq_vec']\n",
    "\n",
    "        \n",
    "    @rec.traingraph.connector.extend\n",
    "    def train_connect(graph):\n",
    "        graph.interactiongraph['label'] = graph.inputgraph['label']\n",
    "\n",
    "\n",
    "    return rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([(0, 1304, 1241478537), (0, 1036, 1241445250)],\n",
       "       dtype=[('user_id', '<i4'), ('item_id', '<i4'), ('ts', '<i4')]),\n",
       " array([(1, 282, 1240944095), (1, 282, 1240943945)],\n",
       "       dtype=[('user_id', '<i4'), ('item_id', '<i4'), ('ts', '<i4')]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset\n",
    "import recsys.dataset as dataset\n",
    "total_users = 992   \n",
    "total_items = 14598\n",
    "train_data = np.load('lastfm_train.npy')\n",
    "test_data = np.load('lastfm_test.npy')\n",
    "train_data[:2], test_data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# hyperparamerters\n",
    "dim_item_embed = 50     # dimension of item embedding\n",
    "max_seq_len = 100       # the maxium length of user's listen history\n",
    "total_iter = int(1e3)   # iterations for training \n",
    "batch_size = 100        # training batch size\n",
    "eval_iter = 100         # iteration of evaluation\n",
    "save_iter = eval_iter   # iteration of saving model   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model\n",
    "model = VanlillaMlpRec(batch_size=batch_size,\n",
    "    total_items=train_dataset.total_items(),\n",
    "    max_seq_len=max_seq_len,\n",
    "    dim_item_embed=dim_item_embed,\n",
    "    save_model_dir='VanlillaMlpRec/',\n",
    "    train=True, \n",
    "    serve=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# evaluators\n",
    "import recsys.metrics.auc as auc\n",
    "import recsys.metrics.recall as recall\n",
    "\n",
    "auc_evaluator = auc.AUC()\n",
    "recall_evaluator = recall.Recall(recall_at=[100, 200, 300, 400, 500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# datasets\n",
    "import recsys.dataset as dataset\n",
    "dataset = imp.reload(dataset)\n",
    "train_dataset = dataset.Dataset(train_data, total_users, total_items, \n",
    "                        sortby='ts', name='Train')\n",
    "test_dataset = dataset.Dataset(test_data, total_users, total_items, \n",
    "                       sortby='ts', name='Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sampler\n",
    "import recsys.samplers.temporal_sampler as temporal_sampler\n",
    "train_sampler = temporal_sampler.create_training_sampler(batch_size=batch_size, max_seq_len=max_seq_len, \n",
    "                                dataset=train_dataset, num_process=1)\n",
    "test_sampler = temporal_sampler.create_evaluation_sampler(dataset=test_dataset, \n",
    "                                         max_seq_len=max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# trainer\n",
    "import recsys.model_trainer as model_trainer\n",
    "model_trainer = imp.reload(model_trainer)\n",
    "trainer = model_trainer.ModelTrainer(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[Training starts, total_iter: 1000, eval_iter: 100, save_iter: 100]\u001b[0m\n",
      "\u001b[31m[iter 100]\u001b[0m Model saved.\n",
      "\u001b[31m[iter 100]\u001b[0m loss: 9.495581\n",
      "\u001b[32m..(dataset: Test) evaluation\u001b[0m\n",
      "INFO:tensorflow:Restoring parameters from VanlillaMlpRec/model.ckpt\n",
      "\u001b[32m..(dataset: Test)\u001b[0m AUC 0.6901089264917449\n",
      "\u001b[32m..(dataset: Test)\u001b[0m Recall 0.06333333333333334 0.09333333333333334 0.13333333333333333 0.16 0.18\n",
      "\u001b[31m[iter 200]\u001b[0m Model saved.\n",
      "\u001b[31m[iter 200]\u001b[0m loss: 9.008132\n",
      "\u001b[32m..(dataset: Test) evaluation\u001b[0m\n",
      "INFO:tensorflow:Restoring parameters from VanlillaMlpRec/model.ckpt\n",
      "\u001b[32m..(dataset: Test)\u001b[0m AUC 0.7058904797789499\n",
      "\u001b[32m..(dataset: Test)\u001b[0m Recall 0.06666666666666667 0.08666666666666667 0.14 0.17 0.19\n",
      "\u001b[31m[iter 300]\u001b[0m Model saved.\n",
      "\u001b[31m[iter 300]\u001b[0m loss: 8.906515\n",
      "\u001b[32m..(dataset: Test) evaluation\u001b[0m\n",
      "INFO:tensorflow:Restoring parameters from VanlillaMlpRec/model.ckpt\n",
      "\u001b[32m..(dataset: Test)\u001b[0m AUC 0.7177821926879953\n",
      "\u001b[32m..(dataset: Test)\u001b[0m Recall 0.07666666666666666 0.10333333333333333 0.13333333333333333 0.18 0.2\n",
      "\u001b[31m[iter 400]\u001b[0m Model saved.\n",
      "\u001b[31m[iter 400]\u001b[0m loss: 8.866875\n",
      "\u001b[32m..(dataset: Test) evaluation\u001b[0m\n",
      "INFO:tensorflow:Restoring parameters from VanlillaMlpRec/model.ckpt\n",
      "\u001b[32m..(dataset: Test)\u001b[0m AUC 0.7305745472814049\n",
      "\u001b[32m..(dataset: Test)\u001b[0m Recall 0.06333333333333334 0.1 0.14333333333333334 0.17333333333333334 0.19666666666666666\n",
      "\u001b[31m[iter 500]\u001b[0m Model saved.\n",
      "\u001b[31m[iter 500]\u001b[0m loss: 8.780353\n",
      "\u001b[32m..(dataset: Test) evaluation\u001b[0m\n",
      "INFO:tensorflow:Restoring parameters from VanlillaMlpRec/model.ckpt\n",
      "\u001b[32m..(dataset: Test)\u001b[0m AUC 0.7370783951040167\n",
      "\u001b[32m..(dataset: Test)\u001b[0m Recall 0.06 0.10666666666666667 0.13666666666666666 0.17333333333333334 0.20333333333333334\n",
      "\u001b[31m[iter 600]\u001b[0m Model saved.\n",
      "\u001b[31m[iter 600]\u001b[0m loss: 8.736734\n",
      "\u001b[32m..(dataset: Test) evaluation\u001b[0m\n",
      "INFO:tensorflow:Restoring parameters from VanlillaMlpRec/model.ckpt\n",
      "\u001b[32m..(dataset: Test)\u001b[0m AUC 0.7416676942750794\n",
      "\u001b[32m..(dataset: Test)\u001b[0m Recall 0.06 0.10666666666666667 0.15666666666666668 0.2 0.20666666666666667\n",
      "\u001b[31m[iter 700]\u001b[0m Model saved.\n",
      "\u001b[31m[iter 700]\u001b[0m loss: 8.725367\n",
      "\u001b[32m..(dataset: Test) evaluation\u001b[0m\n",
      "INFO:tensorflow:Restoring parameters from VanlillaMlpRec/model.ckpt\n",
      "\u001b[32m..(dataset: Test)\u001b[0m AUC 0.7465595670343221\n",
      "\u001b[32m..(dataset: Test)\u001b[0m Recall 0.056666666666666664 0.11333333333333333 0.15666666666666668 0.19 0.21666666666666667\n",
      "\u001b[31m[iter 800]\u001b[0m Model saved.\n",
      "\u001b[31m[iter 800]\u001b[0m loss: 8.690134\n",
      "\u001b[32m..(dataset: Test) evaluation\u001b[0m\n",
      "INFO:tensorflow:Restoring parameters from VanlillaMlpRec/model.ckpt\n",
      "\u001b[32m..(dataset: Test)\u001b[0m AUC 0.7496987965563701\n",
      "\u001b[32m..(dataset: Test)\u001b[0m Recall 0.056666666666666664 0.10333333333333333 0.15666666666666668 0.18666666666666668 0.21333333333333335\n",
      "\u001b[31m[iter 900]\u001b[0m Model saved.\n",
      "\u001b[31m[iter 900]\u001b[0m loss: 8.642936\n",
      "\u001b[32m..(dataset: Test) evaluation\u001b[0m\n",
      "INFO:tensorflow:Restoring parameters from VanlillaMlpRec/model.ckpt\n",
      "\u001b[32m..(dataset: Test)\u001b[0m AUC 0.7516729464958553\n",
      "\u001b[32m..(dataset: Test)\u001b[0m Recall 0.06333333333333334 0.10666666666666667 0.15 0.17666666666666667 0.22666666666666666\n",
      "\u001b[31m[iter 1000]\u001b[0m Model saved.\n",
      "\u001b[31m[iter 1000]\u001b[0m loss: 8.659756\n",
      "\u001b[32m..(dataset: Test) evaluation\u001b[0m\n",
      "INFO:tensorflow:Restoring parameters from VanlillaMlpRec/model.ckpt\n",
      "\u001b[32m..(dataset: Test)\u001b[0m AUC 0.7546331437966706\n",
      "\u001b[32m..(dataset: Test)\u001b[0m Recall 0.06666666666666667 0.10333333333333333 0.15333333333333332 0.18666666666666668 0.23\n"
     ]
    }
   ],
   "source": [
    "# train/test\n",
    "trainer.train(total_iter=total_iter, \n",
    "    eval_iter=eval_iter,\n",
    "    save_iter=save_iter,\n",
    "    train_sampler=train_sampler,\n",
    "    eval_samplers=[test_sampler], \n",
    "    evaluators=[auc_evaluator, recall_evaluator])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
