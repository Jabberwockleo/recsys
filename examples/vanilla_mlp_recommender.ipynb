{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '/home/work/notebook', '/home/work/.ipython', '/home/work/anaconda3/envs/tensorflow_gpuenv/lib/python36.zip', '/home/work/anaconda3/envs/tensorflow_gpuenv/lib/python3.6/site-packages/dataset-1.1.0-py3.6.egg', '/home/work/anaconda3/envs/tensorflow_gpuenv/lib/python3.6/lib-dynload', '/home/work/anaconda3/envs/tensorflow_gpuenv/lib/python3.6/site-packages/IPython/extensions', '/home/work/anaconda3/envs/tensorflow_gpuenv/lib/python3.6/site-packages/normality-1.0.0-py3.6.egg', '/home/work/anaconda3/envs/tensorflow_gpuenv/lib/python3.6/site-packages', '/home/work/anaconda3/envs/tensorflow_gpuenv/lib/python3.6']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "tmp = set(sys.path)\n",
    "tmp.add(\"/home/work/notebook\")\n",
    "sys.path = list(tmp)\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU setup\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download datasets\n",
    "#import urllib.request\n",
    "#dataset_prefix = 'http://s3.amazonaws.com/cornell-tech-sdl-openrec'\n",
    "#urllib.request.urlretrieve('%s/lastfm/lastfm_test.npy' % dataset_prefix, \n",
    "#                   'lastfm_test.npy')\n",
    "#urllib.request.urlretrieve('%s/lastfm/lastfm_train.npy' % dataset_prefix, \n",
    "#                   'lastfm_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import recsys.recommenders.recommender_base as recommender_base\n",
    "import recsys.modules.extractions.embedding_layer as embedding_layer\n",
    "import recsys.modules.interactions.mlp_softmax as mlp_softmax\n",
    "import recsys.modules.fusions.variable_average as variable_average\n",
    "import recsys.modules.fusions.concatenate as concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import imp\n",
    "recommender_base = imp.reload(recommender_base)\n",
    "embedding_layer = imp.reload(embedding_layer)\n",
    "mlp_softmax = imp.reload(mlp_softmax)\n",
    "variable_average = imp.reload(variable_average)\n",
    "concatenate = imp.reload(concatenate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def VanillaMlpRec(batch_size, dim_item_embed, max_seq_len, total_items,\n",
    "        l2_reg_embed=None, l2_reg_mlp=None, dropout=None, init_model_dir=None,\n",
    "        save_model_dir='VanillaMlpRec/', train=True, serve=False):\n",
    "    \n",
    "    rec = recommender_base.Recommender(init_model_dir=init_model_dir,\n",
    "                      save_model_dir=save_model_dir, train=train, serve=serve)\n",
    "    \n",
    "    @rec.traingraph.inputgraph(outs=['seq_item_id', 'seq_len', 'label'])\n",
    "    def train_input_graph(subgraph):\n",
    "      \n",
    "        subgraph['seq_item_id'] = tf.placeholder(tf.int32, \n",
    "                                      shape=[batch_size, max_seq_len],\n",
    "                                      name='seq_item_id')\n",
    "        subgraph['seq_len'] = tf.placeholder(tf.int32, \n",
    "                                      shape=[batch_size], \n",
    "                                      name='seq_len')\n",
    "        subgraph['label'] = tf.placeholder(tf.int32, \n",
    "                                      shape=[batch_size], \n",
    "                                      name='label')\n",
    "        \n",
    "        subgraph.register_global_input_mapping({'seq_item_id': subgraph['seq_item_id'],\n",
    "                                                'seq_len': subgraph['seq_len'],\n",
    "                                                'label': subgraph['label']})\n",
    "        \n",
    "    @rec.servegraph.inputgraph(outs=['seq_item_id', 'seq_len'])\n",
    "    def serve_input_graph(subgraph):\n",
    "        subgraph['seq_item_id'] = tf.placeholder(tf.int32, \n",
    "                                      shape=[None, max_seq_len],\n",
    "                                      name='seq_item_id')\n",
    "        subgraph['seq_len'] = tf.placeholder(tf.int32, \n",
    "                                      shape=[None],\n",
    "                                      name='seq_len')\n",
    "        subgraph.register_global_input_mapping({'seq_item_id': subgraph['seq_item_id'],\n",
    "                                                'seq_len': subgraph['seq_len']})\n",
    "    \n",
    "    @rec.traingraph.itemgraph(ins=['seq_item_id'], outs=['seq_vec'])\n",
    "    @rec.servegraph.itemgraph(ins=['seq_item_id'], outs=['seq_vec'])\n",
    "    def item_graph(subgraph):\n",
    "        _, subgraph['seq_vec']= embedding_layer.apply(l2_reg=l2_reg_embed,\n",
    "                                      init='normal',\n",
    "                                      id_=subgraph['seq_item_id'],\n",
    "                                      shape=[total_items,dim_item_embed],\n",
    "                                      subgraph=subgraph,\n",
    "                                      scope='item')\n",
    "\n",
    "    @rec.traingraph.fusiongraph(ins=['seq_vec', 'seq_len'], outs=['fusion_vec'])\n",
    "    @rec.servegraph.fusiongraph(ins=['seq_vec', 'seq_len'], outs=['fusion_vec'])\n",
    "    def fusion_graph(subgraph):\n",
    "        item_repr = variable_average.apply(sequence=subgraph['seq_vec'], seq_len=subgraph['seq_len'])\n",
    "        fusion_vec = concatenate.apply([item_repr])\n",
    "        subgraph['fusion_vec'] = fusion_vec\n",
    "\n",
    "    @rec.traingraph.interactiongraph(ins=['fusion_vec', 'label'])\n",
    "    def train_interaction_graph(subgraph):\n",
    "        mlp_softmax.apply(\n",
    "            in_tensor=subgraph['fusion_vec'],\n",
    "            dims=[dim_item_embed, total_items],\n",
    "            l2_reg=l2_reg_mlp,\n",
    "            labels=subgraph['label'],\n",
    "            dropout=dropout,\n",
    "            train=True,\n",
    "            subgraph=subgraph,\n",
    "            scope='MLPSoftmax')\n",
    "\n",
    "    @rec.servegraph.interactiongraph(ins=['fusion_vec'])\n",
    "    def serve_interaction_graph(subgraph):\n",
    "        mlp_softmax.apply(\n",
    "            in_tensor=subgraph['fusion_vec'],\n",
    "            dims=[dim_item_embed, total_items],\n",
    "            l2_reg=l2_reg_mlp,\n",
    "            train=False,\n",
    "            subgraph=subgraph,\n",
    "            scope='MLPSoftmax')\n",
    "\n",
    "    @rec.traingraph.optimizergraph\n",
    "    def optimizer_graph(subgraph):\n",
    "        losses = tf.add_n(subgraph.get_global_losses())\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "        subgraph.register_global_operation(optimizer.minimize(losses))\n",
    "\n",
    "    @rec.traingraph.connector\n",
    "    @rec.servegraph.connector\n",
    "    def connect(graph):\n",
    "        graph.itemgraph['seq_item_id'] = graph.inputgraph['seq_item_id']\n",
    "        graph.fusiongraph['seq_len'] = graph.inputgraph['seq_len']\n",
    "        graph.fusiongraph['seq_vec'] = graph.itemgraph['seq_vec']\n",
    "        graph.interactiongraph['fusion_vec'] = graph.fusiongraph['fusion_vec']\n",
    "\n",
    "    @rec.traingraph.connector.extend\n",
    "    def train_connect(graph):\n",
    "        graph.interactiongraph['label'] = graph.inputgraph['label']\n",
    "\n",
    "    return rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "992 14598\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([(0, 1304, 1241478537), (0, 1036, 1241445250)],\n",
       "       dtype=[('user_id', '<i4'), ('item_id', '<i4'), ('ts', '<i4')]),\n",
       " array([(1, 282, 1240944095), (1, 282, 1240943945)],\n",
       "       dtype=[('user_id', '<i4'), ('item_id', '<i4'), ('ts', '<i4')]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset\n",
    "import recsys.dataset as dataset\n",
    "train_data = np.load('lastfm_train.npy')\n",
    "test_data = np.load('lastfm_test.npy')\n",
    "total_users = max(set(list(train_data['user_id']) + list(test_data['user_id']))) + 1\n",
    "total_items = max(set(list(train_data['item_id']) + list(test_data['item_id']))) + 1\n",
    "print(total_users, total_items)\n",
    "train_data[:2], test_data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# datasets\n",
    "import recsys.dataset as dataset\n",
    "dataset = imp.reload(dataset)\n",
    "train_dataset = dataset.Dataset(train_data, total_users, total_items, \n",
    "                        sortby='ts', name='Train')\n",
    "test_dataset = dataset.Dataset(test_data, total_users, total_items, \n",
    "                       sortby='ts', name='Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# hyperparamerters\n",
    "dim_item_embed = 50     # dimension of item embedding\n",
    "max_seq_len = 100       # the maxium length of user's listen history\n",
    "total_iter = int(1e3)   # iterations for training \n",
    "batch_size = 100        # training batch size\n",
    "eval_iter = 200         # iteration of evaluation\n",
    "save_iter = eval_iter   # iteration of saving model   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model\n",
    "model = VanillaMlpRec(batch_size=batch_size,\n",
    "    total_items=train_dataset.total_items(),\n",
    "    max_seq_len=max_seq_len,\n",
    "    dim_item_embed=dim_item_embed,\n",
    "    save_model_dir='VanillaMlpRec/',\n",
    "    train=True, \n",
    "    serve=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# evaluators\n",
    "import recsys.metrics.auc as auc\n",
    "import recsys.metrics.ndcg as ndcg\n",
    "import recsys.metrics.recall as recall\n",
    "import recsys.metrics.precision as precision\n",
    "\n",
    "auc_evaluator = auc.AUC()\n",
    "ndcg_evaluator = ndcg.NDCG(ndcg_at=[100])\n",
    "recall_evaluator = recall.Recall(recall_at=[100, 200, 300, 400, 500])\n",
    "precision_evaluator = precision.Precision(precision_at=[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sampler\n",
    "import recsys.samplers.temporal_sampler as temporal_sampler\n",
    "train_sampler = temporal_sampler.create_training_sampler(batch_size=batch_size, max_seq_len=max_seq_len, \n",
    "                                dataset=train_dataset, num_process=1)\n",
    "test_sampler = temporal_sampler.create_evaluation_sampler(dataset=test_dataset, \n",
    "                                         max_seq_len=max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# trainer\n",
    "import recsys.model_trainer as model_trainer\n",
    "model_trainer = imp.reload(model_trainer)\n",
    "trainer = model_trainer.ModelTrainer(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[Training starts, total_iter: 1000, eval_iter: 200, save_iter: 200]\u001b[0m\n",
      "\u001b[31m[iter 200]\u001b[0m Model saved.\n",
      "\u001b[31m[iter 200]\u001b[0m loss: 9.227559\n",
      "\u001b[32m..(dataset: Test) evaluation\u001b[0m\n",
      "INFO:tensorflow:Restoring parameters from VanillaMlpRec/model.ckpt\n",
      "\u001b[32m..(dataset: Test)\u001b[0m AUC 0.719282044255669\n",
      "\u001b[32m..(dataset: Test)\u001b[0m NDCG 0.015674682791214544\n",
      "\u001b[32m..(dataset: Test)\u001b[0m Recall 0.06333333333333334 0.11333333333333333 0.13333333333333333 0.16666666666666666 0.21\n",
      "\u001b[32m..(dataset: Test)\u001b[0m Precision 0.0006333333333333333\n",
      "\u001b[31m[iter 400]\u001b[0m Model saved.\n",
      "\u001b[31m[iter 400]\u001b[0m loss: 8.882123\n",
      "\u001b[32m..(dataset: Test) evaluation\u001b[0m\n",
      "INFO:tensorflow:Restoring parameters from VanillaMlpRec/model.ckpt\n",
      "\u001b[32m..(dataset: Test)\u001b[0m AUC 0.7408312210271517\n",
      "\u001b[32m..(dataset: Test)\u001b[0m NDCG 0.014803545130783838\n",
      "\u001b[32m..(dataset: Test)\u001b[0m Recall 0.056666666666666664 0.11333333333333333 0.16333333333333333 0.19 0.21333333333333335\n",
      "\u001b[32m..(dataset: Test)\u001b[0m Precision 0.0005666666666666667\n",
      "\u001b[31m[iter 600]\u001b[0m Model saved.\n",
      "\u001b[31m[iter 600]\u001b[0m loss: 8.790908\n",
      "\u001b[32m..(dataset: Test) evaluation\u001b[0m\n",
      "INFO:tensorflow:Restoring parameters from VanillaMlpRec/model.ckpt\n",
      "\u001b[32m..(dataset: Test)\u001b[0m AUC 0.7460400538923523\n",
      "\u001b[32m..(dataset: Test)\u001b[0m NDCG 0.014008616315461454\n",
      "\u001b[32m..(dataset: Test)\u001b[0m Recall 0.05333333333333334 0.11 0.13666666666666666 0.17333333333333334 0.21333333333333335\n",
      "\u001b[32m..(dataset: Test)\u001b[0m Precision 0.0005333333333333334\n",
      "\u001b[31m[iter 800]\u001b[0m Model saved.\n",
      "\u001b[31m[iter 800]\u001b[0m loss: 8.711631\n",
      "\u001b[32m..(dataset: Test) evaluation\u001b[0m\n",
      "INFO:tensorflow:Restoring parameters from VanillaMlpRec/model.ckpt\n",
      "\u001b[32m..(dataset: Test)\u001b[0m AUC 0.7551857687652714\n",
      "\u001b[32m..(dataset: Test)\u001b[0m NDCG 0.015320073654707549\n",
      "\u001b[32m..(dataset: Test)\u001b[0m Recall 0.06 0.11666666666666667 0.13666666666666666 0.17666666666666667 0.21333333333333335\n",
      "\u001b[32m..(dataset: Test)\u001b[0m Precision 0.0006\n",
      "\u001b[31m[iter 1000]\u001b[0m Model saved.\n",
      "\u001b[31m[iter 1000]\u001b[0m loss: 8.660677\n",
      "\u001b[32m..(dataset: Test) evaluation\u001b[0m\n",
      "INFO:tensorflow:Restoring parameters from VanillaMlpRec/model.ckpt\n",
      "\u001b[32m..(dataset: Test)\u001b[0m AUC 0.7575716471421068\n",
      "\u001b[32m..(dataset: Test)\u001b[0m NDCG 0.015156053232358715\n",
      "\u001b[32m..(dataset: Test)\u001b[0m Recall 0.06666666666666667 0.11333333333333333 0.14333333333333334 0.17666666666666667 0.22666666666666666\n",
      "\u001b[32m..(dataset: Test)\u001b[0m Precision 0.0006666666666666668\n"
     ]
    }
   ],
   "source": [
    "# train/test\n",
    "trainer.train(total_iter=total_iter, \n",
    "    eval_iter=eval_iter,\n",
    "    save_iter=save_iter,\n",
    "    train_sampler=train_sampler,\n",
    "    eval_samplers=[test_sampler], \n",
    "    evaluators=[auc_evaluator, ndcg_evaluator, recall_evaluator, precision_evaluator])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
