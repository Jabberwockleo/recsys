{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '/home/work/anaconda3/envs/tensorflow_gpuenv/lib/python3.6/site-packages/IPython/extensions', '/home/work/anaconda3/envs/tensorflow_gpuenv/lib/python3.6/site-packages/dataset-1.1.0-py3.6.egg', '/home/work/anaconda3/envs/tensorflow_gpuenv/lib/python3.6/site-packages', '/home/work/anaconda3/envs/tensorflow_gpuenv/lib/python3.6/site-packages/normality-1.0.0-py3.6.egg', '/home/work/.ipython', '/home/work/notebook', '/home/work/anaconda3/envs/tensorflow_gpuenv/lib/python36.zip', '/home/work/anaconda3/envs/tensorflow_gpuenv/lib/python3.6/lib-dynload', '/home/work/anaconda3/envs/tensorflow_gpuenv/lib/python3.6']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "tmp = set(sys.path)\n",
    "tmp.add(\"/home/work/notebook\")\n",
    "sys.path = list(tmp)\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU setup\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download datasets\n",
    "#import urllib.request\n",
    "#dataset_prefix = 'http://s3.amazonaws.com/cornell-tech-sdl-openrec'\n",
    "#urllib.request.urlretrieve('%s/lastfm/lastfm_test.npy' % dataset_prefix, \n",
    "#                   'lastfm_test.npy')\n",
    "#urllib.request.urlretrieve('%s/lastfm/lastfm_train.npy' % dataset_prefix, \n",
    "#                   'lastfm_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import recsys.recommenders.recommender_base as recommender_base\n",
    "import recsys.modules.extractions.embedding_layer as embedding_layer\n",
    "import recsys.modules.interactions.rnn_softmax as rnn_softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import imp\n",
    "recommender_base = imp.reload(recommender_base)\n",
    "embedding_layer = imp.reload(embedding_layer)\n",
    "rnn_softmax = imp.reload(rnn_softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def VanillaRnnRec(batch_size, dim_item_embed, max_seq_len, total_items, num_units,\n",
    "        l2_reg_embed=None, init_model_dir=None,\n",
    "        save_model_dir='VanillaRnnRec/', train=True, serve=False):\n",
    "    \n",
    "    rec = recommender_base.Recommender(init_model_dir=init_model_dir,\n",
    "                      save_model_dir=save_model_dir, train=train, serve=serve)\n",
    "    \n",
    "    @rec.traingraph.inputgraph(outs=['seq_item_id', 'seq_len', 'label'])\n",
    "    def train_input_graph(subgraph):\n",
    "        subgraph['seq_item_id'] = tf.placeholder(tf.int32, \n",
    "                                      shape=[batch_size, max_seq_len],\n",
    "                                      name='seq_item_id')\n",
    "        subgraph['seq_len'] = tf.placeholder(tf.int32, \n",
    "                                      shape=[batch_size], \n",
    "                                      name='seq_len')\n",
    "        subgraph['label'] = tf.placeholder(tf.int32, \n",
    "                                      shape=[batch_size], \n",
    "                                      name='label')\n",
    "        subgraph.register_global_input_mapping({'seq_item_id': subgraph['seq_item_id'],\n",
    "                                                'seq_len': subgraph['seq_len'],\n",
    "                                                'label': subgraph['label']})\n",
    "        \n",
    "    @rec.servegraph.inputgraph(outs=['seq_item_id', 'seq_len'])\n",
    "    def serve_input_graph(subgraph):\n",
    "        subgraph['seq_item_id'] = tf.placeholder(tf.int32, \n",
    "                                      shape=[None, max_seq_len],\n",
    "                                      name='seq_item_id')\n",
    "        subgraph['seq_len'] = tf.placeholder(tf.int32, \n",
    "                                      shape=[None],\n",
    "                                      name='seq_len')\n",
    "        subgraph.register_global_input_mapping({'seq_item_id': subgraph['seq_item_id'],\n",
    "                                                'seq_len': subgraph['seq_len']})\n",
    "    \n",
    "    @rec.traingraph.itemgraph(ins=['seq_item_id'], outs=['seq_vec'])\n",
    "    @rec.servegraph.itemgraph(ins=['seq_item_id'], outs=['seq_vec'])\n",
    "    def item_graph(subgraph):\n",
    "        _, subgraph['seq_vec']= embedding_layer.apply(l2_reg=l2_reg_embed,\n",
    "                                      init='normal',\n",
    "                                      id_=subgraph['seq_item_id'],\n",
    "                                      shape=[total_items, dim_item_embed],\n",
    "                                      subgraph=subgraph,\n",
    "                                      scope='item')\n",
    "\n",
    "    @rec.traingraph.interactiongraph(ins=['seq_vec', 'seq_len', 'label'])\n",
    "    def train_interaction_graph(subgraph):\n",
    "        rnn_softmax.apply(\n",
    "            sequence=subgraph['seq_vec'], \n",
    "            seq_len=subgraph['seq_len'], \n",
    "            num_units=num_units, \n",
    "            cell_type='lstm',\n",
    "            total_items=total_items, \n",
    "            label=subgraph['label'], \n",
    "            train=True, \n",
    "            subgraph=subgraph, \n",
    "            scope='RNNSoftmax')\n",
    "\n",
    "    @rec.servegraph.interactiongraph(ins=['seq_vec', 'seq_len'])\n",
    "    def serve_interaction_graph(subgraph):\n",
    "        rnn_softmax.apply(\n",
    "            sequence=subgraph['seq_vec'], \n",
    "            seq_len=subgraph['seq_len'],\n",
    "            num_units=num_units,\n",
    "            cell_type='lstm',\n",
    "            total_items=total_items, \n",
    "            train=False, \n",
    "            subgraph=subgraph, \n",
    "            scope='RNNSoftmax')\n",
    "\n",
    "    @rec.traingraph.optimizergraph\n",
    "    def optimizer_graph(subgraph):\n",
    "        losses = tf.add_n(subgraph.get_global_losses())\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "        subgraph.register_global_operation(optimizer.minimize(losses))\n",
    "\n",
    "    @rec.traingraph.connector\n",
    "    @rec.servegraph.connector\n",
    "    def connect(graph):\n",
    "        graph.itemgraph['seq_item_id'] = graph.inputgraph['seq_item_id']\n",
    "        graph.interactiongraph['seq_len'] = graph.inputgraph['seq_len']\n",
    "        graph.interactiongraph['seq_vec'] = graph.itemgraph['seq_vec']\n",
    "\n",
    "    @rec.traingraph.connector.extend\n",
    "    def train_connect(graph):\n",
    "        graph.interactiongraph['label'] = graph.inputgraph['label']\n",
    "\n",
    "    return rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "992 14598\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([(0, 1304, 1241478537), (0, 1036, 1241445250)],\n",
       "       dtype=[('user_id', '<i4'), ('item_id', '<i4'), ('ts', '<i4')]),\n",
       " array([(1, 282, 1240944095), (1, 282, 1240943945)],\n",
       "       dtype=[('user_id', '<i4'), ('item_id', '<i4'), ('ts', '<i4')]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset\n",
    "import recsys.dataset as dataset\n",
    "train_data = np.load('lastfm_train.npy')\n",
    "test_data = np.load('lastfm_test.npy')\n",
    "total_users = max(set(list(train_data['user_id']) + list(test_data['user_id']))) + 1\n",
    "total_items = max(set(list(train_data['item_id']) + list(test_data['item_id']))) + 1\n",
    "print(total_users, total_items)\n",
    "train_data[:2], test_data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# datasets\n",
    "import recsys.dataset as dataset\n",
    "dataset = imp.reload(dataset)\n",
    "train_dataset = dataset.Dataset(train_data, total_users, total_items, \n",
    "                        sortby='ts', name='Train')\n",
    "test_dataset = dataset.Dataset(test_data, total_users, total_items, \n",
    "                       sortby='ts', name='Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# hyperparamerters\n",
    "dim_item_embed = 50     # dimension of item embedding\n",
    "max_seq_len = 100       # the maxium length of user's listen history\n",
    "num_units = 32          # Number of units in the RNN model\n",
    "total_iter = int(1e3)   # iterations for training \n",
    "batch_size = 64        # training batch size\n",
    "eval_iter = 200         # iteration of evaluation\n",
    "save_iter = eval_iter   # iteration of saving model   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model\n",
    "model = VanillaRnnRec(batch_size=batch_size, \n",
    "    dim_item_embed=dim_item_embed, \n",
    "    max_seq_len=max_seq_len, \n",
    "    total_items=train_dataset.total_items(), \n",
    "    num_units=num_units, \n",
    "    save_model_dir='VanillaRnnRec', \n",
    "    train=True, serve=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# evaluators\n",
    "import recsys.metrics.auc as auc\n",
    "import recsys.metrics.ndcg as ndcg\n",
    "import recsys.metrics.recall as recall\n",
    "import recsys.metrics.precision as precision\n",
    "\n",
    "auc_evaluator = auc.AUC()\n",
    "ndcg_evaluator = ndcg.NDCG(ndcg_at=[100])\n",
    "recall_evaluator = recall.Recall(recall_at=[100, 200, 300, 400, 500])\n",
    "precision_evaluator = precision.Precision(precision_at=[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sampler\n",
    "import recsys.samplers.temporal_sampler as temporal_sampler\n",
    "train_sampler = temporal_sampler.create_training_sampler(batch_size=batch_size, max_seq_len=max_seq_len, \n",
    "    dataset=train_dataset, num_process=1)\n",
    "test_sampler = temporal_sampler.create_evaluation_sampler(dataset=test_dataset, max_seq_len=max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# trainer\n",
    "import recsys.model_trainer as model_trainer\n",
    "model_trainer = imp.reload(model_trainer)\n",
    "trainer = model_trainer.ModelTrainer(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[Training starts, total_iter: 1000, eval_iter: 200, save_iter: 200]\u001b[0m\n",
      "\u001b[31m[iter 200]\u001b[0m Model saved.\n",
      "\u001b[31m[iter 200]\u001b[0m loss: 9.184467\n",
      "\u001b[32m..(dataset: Test) evaluation\u001b[0m\n",
      "INFO:tensorflow:Restoring parameters from VanillaRnnRec/model.ckpt\n",
      "\u001b[32m..(dataset: Test)\u001b[0m AUC 0.7251238839030851\n",
      "\u001b[32m..(dataset: Test)\u001b[0m NDCG 0.012085527505495257\n",
      "\u001b[32m..(dataset: Test)\u001b[0m Recall 0.05333333333333334 0.11666666666666667 0.17333333333333334 0.20666666666666667 0.23333333333333334\n",
      "\u001b[32m..(dataset: Test)\u001b[0m Precision 0.0005333333333333335\n",
      "\u001b[31m[iter 400]\u001b[0m Model saved.\n",
      "\u001b[31m[iter 400]\u001b[0m loss: 8.896507\n",
      "\u001b[32m..(dataset: Test) evaluation\u001b[0m\n",
      "INFO:tensorflow:Restoring parameters from VanillaRnnRec/model.ckpt\n",
      "\u001b[32m..(dataset: Test)\u001b[0m AUC 0.7498970108013062\n",
      "\u001b[32m..(dataset: Test)\u001b[0m NDCG 0.013850202482113435\n",
      "\u001b[32m..(dataset: Test)\u001b[0m Recall 0.056666666666666664 0.10666666666666667 0.17333333333333334 0.21 0.23666666666666666\n",
      "\u001b[32m..(dataset: Test)\u001b[0m Precision 0.0005666666666666666\n",
      "\u001b[31m[iter 600]\u001b[0m Model saved.\n",
      "\u001b[31m[iter 600]\u001b[0m loss: 8.796550\n",
      "\u001b[32m..(dataset: Test) evaluation\u001b[0m\n",
      "INFO:tensorflow:Restoring parameters from VanillaRnnRec/model.ckpt\n",
      "\u001b[32m..(dataset: Test)\u001b[0m AUC 0.7510002055216825\n",
      "\u001b[32m..(dataset: Test)\u001b[0m NDCG 0.013794222057408587\n",
      "\u001b[32m..(dataset: Test)\u001b[0m Recall 0.06333333333333334 0.11333333333333333 0.15 0.18666666666666668 0.21666666666666667\n",
      "\u001b[32m..(dataset: Test)\u001b[0m Precision 0.0006333333333333333\n",
      "\u001b[31m[iter 800]\u001b[0m Model saved.\n",
      "\u001b[31m[iter 800]\u001b[0m loss: 8.755205\n",
      "\u001b[32m..(dataset: Test) evaluation\u001b[0m\n",
      "INFO:tensorflow:Restoring parameters from VanillaRnnRec/model.ckpt\n",
      "\u001b[32m..(dataset: Test)\u001b[0m AUC 0.7575912858806604\n",
      "\u001b[32m..(dataset: Test)\u001b[0m NDCG 0.011307643227090021\n",
      "\u001b[32m..(dataset: Test)\u001b[0m Recall 0.05333333333333334 0.1 0.14666666666666667 0.19666666666666666 0.22333333333333333\n",
      "\u001b[32m..(dataset: Test)\u001b[0m Precision 0.0005333333333333334\n",
      "\u001b[31m[iter 1000]\u001b[0m Model saved.\n",
      "\u001b[31m[iter 1000]\u001b[0m loss: 8.699480\n",
      "\u001b[32m..(dataset: Test) evaluation\u001b[0m\n",
      "INFO:tensorflow:Restoring parameters from VanillaRnnRec/model.ckpt\n",
      "\u001b[32m..(dataset: Test)\u001b[0m AUC 0.7587403804434703\n",
      "\u001b[32m..(dataset: Test)\u001b[0m NDCG 0.013240340447194151\n",
      "\u001b[32m..(dataset: Test)\u001b[0m Recall 0.05 0.10333333333333333 0.14333333333333334 0.18333333333333332 0.21\n",
      "\u001b[32m..(dataset: Test)\u001b[0m Precision 0.0005\n"
     ]
    }
   ],
   "source": [
    "# train/test\n",
    "trainer.train(total_iter=total_iter, \n",
    "    eval_iter=eval_iter,\n",
    "    save_iter=save_iter,\n",
    "    train_sampler=train_sampler,\n",
    "    eval_samplers=[test_sampler], \n",
    "    evaluators=[auc_evaluator, ndcg_evaluator, recall_evaluator, precision_evaluator])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serve\n",
    "serve_sampler = temporal_sampler.create_evaluation_sampler(dataset=test_dataset, max_seq_len=max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([957],\n",
       " array([([ 7553,  1868, 12984,  2195,  9865,  2104,   833, 13487,   498,   606,  8813,  2019,  5007,  1161,  2247,   322,   119,  4429,  1323,  1087,  9298,   469,  1972,   905,    42, 13883,  1710,  2908,  1482,   964,  2604,  1057,  2482,   279,   551,  3667,  3035,  4282,   823,  5059,    66,  2181,   420,   488,  3322,   976,  1530,  1411, 13244,  1063,  4714,  8850,  2865,    41,  1249,    81,  5502,  1869, 12974,  5697,   354, 12359,  1422,   124,   181,  5854,   935,   648,  2692,   743,  2588, 14444,  2406,  4202,  2404,  6703,  6826, 10896,  1348,   108,  6509,   966,  2895,   707,  1424,  9096,   259,  1164,  4381,   535,  2607,  5953,  7507,  2550,  2431,   283,  3659,  7069,  5322,   957], 100)],\n",
       "       dtype=[('seq_item_id', '<i4', (100,)), ('seq_len', '<i4')]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbl, input_data = serve_sampler.next_batch()\n",
    "lbl, input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: {'losses': [], 'outputs': [array([ 0.60049284,  0.49547878,  0.23498696, ..., -2.1666248 ,\n",
      "       -2.0712152 , -3.2872112 ], dtype=float32)]}\n",
      "indices: [  1 110  40  38  62  15  35  71  36   4  75  16  83  27  42  33   0  30\n",
      "  63   3]\n",
      "probs: [0.49547878 0.49794176 0.5048535  0.506617   0.5095771  0.51044035\n",
      " 0.5251231  0.5286194  0.53370965 0.5420119  0.5465682  0.5520555\n",
      " 0.56734854 0.5715802  0.5928797  0.5964658  0.60049284 0.61573917\n",
      " 0.62040275 0.6322938 ]\n"
     ]
    }
   ],
   "source": [
    "output_dict = model.serve(batch_data=input_data)\n",
    "print(\"outputs:\", output_dict)\n",
    "predict_proba = output_dict['outputs'][0].ravel()\n",
    "ind_largest = np.argsort(predict_proba)[-20:]\n",
    "print(\"indices:\", ind_largest)\n",
    "print(\"probs:\", predict_proba[ind_largest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'VanillaRnnRec_exported_pb/saved_model.pb'\n"
     ]
    }
   ],
   "source": [
    "# export\n",
    "model.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from b'VanillaRnnRec_exported_pb/variables/variables'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'y_0': array([ 0.60049284,  0.49547878,  0.23498696, ..., -2.1666248 ,\n",
       "        -2.0712152 , -3.2872112 ], dtype=float32)}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict using pb model\n",
    "model.predict_pb(feed_name_dict={\n",
    "    'seq_item_id': input_data['seq_item_id'],\n",
    "    'seq_len': input_data['seq_len']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
